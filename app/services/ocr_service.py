# app/services/ocr_service.py

import os
import re
import cv2
import pandas as pd
import numpy as np
from tqdm import tqdm
from paddleocr import PaddleOCR
from .pdf_service import find_text_coordinates, extract_text_from_coords


# --- íƒœê·¸ ì •ê·œì‹ (í•µì‹¬) ---
# ì˜ˆì‹œ ë§¤ì¹­: "AA-123B", "AA 123 B", "aa123", "P-1001", "T 25"
# - ì˜ë¬¸ prefix 1~6ì
# - êµ¬ë¶„ì(ê³µë°±/í•˜ì´í”ˆ/ì–¸ë”ìŠ¤ì½”ì–´/ì ) í—ˆìš©
# - ìˆ«ì 1~6ìë¦¬
# - ì„ íƒì  suffix(ì˜ë¬¸ 1~3ì)
TAG_PATTERN = re.compile(
    r'(?<![A-Za-z0-9])'           # ì™¼ìª½ ê²½ê³„ê°€ ì˜ìˆ«ì ì•„ë‹˜
    r'([A-Za-z]{1,6})'            # prefix
    r'[\s\-_\.]*'                 # êµ¬ë¶„ì
    r'([0-9]{1,6})'               # number
    r'(?:[\s\-_\.]*([A-Za-z]{1,3}))?'  # optional suffix
    r'(?![A-Za-z0-9])',           # ì˜¤ë¥¸ìª½ ê²½ê³„ê°€ ì˜ìˆ«ì ì•„ë‹˜
    re.IGNORECASE
)

def _normalize_tag_string(raw_text: str):
    """
    OCR ê²°ê³¼ ë¬¸ìì—´ì—ì„œ íƒœê·¸ íŒ¨í„´ì„ ì°¾ì•„ ì •ê·œí™”ëœ íƒœê·¸ì™€ ì»´í¬ë„ŒíŠ¸ë¥¼ ë°˜í™˜.
    ë°˜í™˜: (normalized, prefix, number, suffix) ë˜ëŠ” (None, None, None, None)
    normalized ì˜ˆ: 'AA-123B' (suffix ì—†ìœ¼ë©´ 'AA-123')
    """
    if not raw_text:
        return (None, None, None, None)

    # ì•½í•œ ë…¸ì´ì¦ˆ ì œê±° (ìœ ì‚¬ êµ¬ë¶„ì í†µì¼)
    cleaned = raw_text.replace('â€”', '-').replace('â€“', '-').replace('Â·', '.')
    cleaned = re.sub(r'\s+', ' ', cleaned)  # ê³µë°± ì••ì¶•

    m = TAG_PATTERN.search(cleaned)
    if not m:
        return (None, None, None, None)

    pref = (m.group(1) or '').upper()
    num  = (m.group(2) or '')
    suf  = (m.group(3) or '')
    sufU = suf.upper() if suf else ''

    normalized = f"{pref}-{num}{sufU}" if sufU else f"{pref}-{num}"
    return (normalized, pref, num, sufU)


# --- PaddleOCR ì‹±ê¸€í„´ ---
_OCR_SINGLETON = None
def _get_ocr():
    global _OCR_SINGLETON
    if _OCR_SINGLETON is None:
        print("PaddleOCR ëª¨ë¸ì„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...")
        _OCR_SINGLETON = PaddleOCR(
            use_doc_orientation_classify=False,
            use_doc_unwarping=False,
            use_textline_orientation=False
        )
    return _OCR_SINGLETON


def _safe_crop(img: np.ndarray, x1: int, y1: int, x2: int, y2: int) -> np.ndarray:
    h, w = img.shape[:2]
    x1 = max(0, min(x1, w - 1))
    x2 = max(0, min(x2, w))
    y1 = max(0, min(y1, h - 1))
    y2 = max(0, min(y2, h))
    if x2 <= x1 or y2 <= y1:
        return None
    crop = img[y1:y2, x1:x2]
    if crop is None or crop.size == 0 or crop.shape[0] < 2 or crop.shape[1] < 2:
        return None
    return crop


def _parse_paddle_result(ocr_result) -> str:
    """
    PaddleOCR ê²°ê³¼ë¥¼ ë²„ì „ë³„ í¬ë§· ì°¨ì´ì— ê²¬ê³ í•˜ê²Œ íŒŒì‹±í•˜ì—¬ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ.
    """
    if not ocr_result:
        return ""

    texts = []

    first = ocr_result[0]
    # dict í¬ë§· (predict() ê³„ì—´)
    if isinstance(first, dict):
        for key in ('rec_texts', 'texts'):
            v = first.get(key)
            if isinstance(v, list):
                return " ".join(map(str, v)).strip()

        arr = first.get('res') or []
        if isinstance(arr, list):
            for line in arr:
                try:
                    if isinstance(line, list) and len(line) >= 2:
                        val = line[1]
                        if isinstance(val, (tuple, list)) and len(val) >= 1:
                            texts.append(str(val[0]))
                        elif isinstance(val, str):
                            texts.append(val)
                except Exception:
                    continue
        return " ".join(texts).strip()

    # list í¬ë§· ([ [[pts]], (text, score) ] ...)
    for line in ocr_result:
        try:
            if isinstance(line, list) and len(line) >= 2:
                val = line[1]
                if isinstance(val, (tuple, list)) and len(val) >= 1:
                    texts.append(str(val[0]))
                elif isinstance(val, str):
                    texts.append(val)
        except Exception:
            continue
    return " ".join(texts).strip()


def perform_ocr_on_detections_and_export(detection_results: list, output_excel_path: str,
                                         pdf_path: str, reference_text: str, reference_page: int,
                                         class_names: list):
    """
    íƒì§€ëœ ê°ì²´ë“¤ì— ëŒ€í•´ ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ OCRì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥.
    + íƒœê·¸ ì •ê·œì‹ ê¸°ë°˜ ì •ì œ ì»¬ëŸ¼ ì¶”ê°€ (í•µì‹¬ ë°˜ì˜)
    ì¶œë ¥ ì»¬ëŸ¼:
      ["PID NO", "Original Page", "Object Index", "Class Name", "Detection Score",
       "Recognized Text", "Tag Matched", "Tag (Normalized)", "Tag_Prefix", "Tag_Number", "Tag_Suffix"]
    """

    # --- PID NO ì¶”ì¶œ ---
    pid_no_map = {}
    print(f"ê¸°ì¤€ í…ìŠ¤íŠ¸ '{reference_text}'ì˜ ì¢Œí‘œë¥¼ {reference_page} í˜ì´ì§€ì—ì„œ ì°¾ëŠ” ì¤‘...")
    pid_no_coords = find_text_coordinates(pdf_path, reference_text, reference_page)

    if not pid_no_coords:
        print("âš ï¸ ê¸°ì¤€ í…ìŠ¤íŠ¸ì˜ ì¢Œí‘œë¥¼ ì°¾ì§€ ëª»í•´ PID NO ì¶”ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    else:
        print(f"ì¢Œí‘œ ì°¾ìŒ: {pid_no_coords}. ëª¨ë“  í˜ì´ì§€ì—ì„œ í•´ë‹¹ ì¢Œí‘œì˜ PID NOë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
        import fitz
        doc = fitz.open(pdf_path)
        for i, _ in enumerate(doc):
            page_key = f"page_{i:03d}"
            pid_no = extract_text_from_coords(pdf_path, i, pid_no_coords, reference_text)
            pid_no_map[page_key] = pid_no
        doc.close()

    # --- OCR ì¸ìŠ¤í„´ìŠ¤ ---
    ocr = _get_ocr()

    # --- ì´ ê°ì²´ ìˆ˜ í™•ì¸ ---
    total_detections = sum(len(res.get('detections', [])) for res in detection_results if res.get('success'))
    if total_detections == 0:
        print("âš ï¸ íƒì§€ëœ ê°ì²´ê°€ ì—†ì–´ OCRì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        cols = ["PID NO", "Original Page", "Object Index", "Class Name", "Detection Score",
                "Recognized Text", "Tag Matched", "Tag (Normalized)", "Tag_Prefix", "Tag_Number", "Tag_Suffix"]
        df = pd.DataFrame(columns=cols)
        os.makedirs(os.path.dirname(output_excel_path), exist_ok=True)
        df.to_excel(output_excel_path, index=False, engine='openpyxl')
        return

    print(f"ğŸ“ ì´ {total_detections}ê°œ íƒì§€ëœ ê°ì²´ì— ëŒ€í•´ OCR ìˆ˜í–‰ ì¤‘...")

    rows = []

    for result in tqdm(detection_results, desc="í˜ì´ì§€ë³„ OCR ì²˜ë¦¬"):
        if not result.get('success') or not result.get('detections'):
            continue

        # ë©”ëª¨ë¦¬ ì´ë¯¸ì§€ ìš°ì„  ì‚¬ìš©
        full_image = result.get('image_ndarray')
        image_path = result.get('image_path')
        if full_image is None:
            full_image = cv2.imread(image_path)
        if full_image is None:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            continue

        base_name = os.path.splitext(os.path.basename(image_path))[0]  # "page_000"
        original_page_key = base_name
        pid_no = pid_no_map.get(original_page_key, "N/A")

        for obj_idx, (x1, y1, x2, y2, score, label_id) in enumerate(result['detections']):
            try:
                crop = _safe_crop(full_image, x1, y1, x2, y2)
                if crop is None:
                    print(f"âš ï¸ ì˜ëª»ëœ crop í¬ê¸°: {image_path}, ê°ì²´ {obj_idx}")
                    continue

                # OCR ìˆ˜í–‰
                ocr_result = ocr.ocr(crop)
                recognized_text = _parse_paddle_result(ocr_result).strip()

                # --- íƒœê·¸ ì •ê·œì‹ ì •ì œ (í•µì‹¬) ---
                normalized, pref, num, suf = _normalize_tag_string(recognized_text)
                tag_matched = bool(normalized)

                # í´ë˜ìŠ¤ëª… ì•ˆì „ ì¡°íšŒ
                if 0 <= int(label_id) < len(class_names):
                    cls_name = class_names[int(label_id)]
                else:
                    cls_name = str(label_id)

                rows.append({
                    "PID NO": pid_no,
                    "Original Page": original_page_key,
                    "Object Index": obj_idx,
                    "Class Name": cls_name,
                    "Detection Score": round(float(score), 3),
                    "Recognized Text": recognized_text,
                    "Tag Matched": tag_matched,
                    "Tag (Normalized)": normalized or "",
                    "Tag_Prefix": pref or "",
                    "Tag_Number": num or "",
                    "Tag_Suffix": suf or ""
                })

            except Exception as e:
                print(f"âš ï¸ OCR ì²˜ë¦¬ ì˜¤ë¥˜ ({image_path}, ê°ì²´ {obj_idx}): {e}")
                if 0 <= int(label_id) < len(class_names):
                    cls_name = class_names[int(label_id)]
                else:
                    cls_name = "Unknown"
                rows.append({
                    "PID NO": pid_no,
                    "Original Page": original_page_key,
                    "Object Index": obj_idx,
                    "Class Name": cls_name,
                    "Detection Score": round(float(score), 3),
                    "Recognized Text": f"OCR Error: {e}",
                    "Tag Matched": False,
                    "Tag (Normalized)": "",
                    "Tag_Prefix": "",
                    "Tag_Number": "",
                    "Tag_Suffix": ""
                })

    # --- ê²°ê³¼ ì €ì¥ (ì •ì œ ì»¬ëŸ¼ í¬í•¨) ---
    os.makedirs(os.path.dirname(output_excel_path), exist_ok=True)
    cols = ["PID NO", "Original Page", "Object Index", "Class Name", "Detection Score",
            "Recognized Text", "Tag Matched", "Tag (Normalized)", "Tag_Prefix", "Tag_Number", "Tag_Suffix"]

    if rows:
        df = pd.DataFrame(rows, columns=cols)
        df.to_excel(output_excel_path, index=False, engine='openpyxl')
        print(f"\nâœ… OCR + íƒœê·¸ ì •ì œ ê²°ê³¼ê°€ '{output_excel_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“Š ì´ {len(rows)}ê°œ ê°ì²´ ì²˜ë¦¬ ì™„ë£Œ (íƒœê·¸ ë§¤ì¹­: {sum(1 for r in rows if r['Tag Matched'])}ê±´)")
    else:
        df = pd.DataFrame(columns=cols)
        df.to_excel(output_excel_path, index=False, engine='openpyxl')
        print("âš ï¸ OCR ê²°ê³¼ê°€ ë¹„ì–´ ìˆê±°ë‚˜ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
